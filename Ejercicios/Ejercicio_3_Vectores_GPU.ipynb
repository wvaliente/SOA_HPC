{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ejercicio_3_Vectores_GPU.ipynb","provenance":[{"file_id":"/v2/external/notebooks/basic_features_overview.ipynb","timestamp":1601321037647}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Zw-Vno_15t-E"},"source":["# SOA - TP3 - Parte 3\n","\n","Para este ejercicio se realizarán practicas con GPGPU. En esta parte, se planificarán los kernels del GPU, con hilos sobre $1$ multi-dimensión. El tema que se utilizará es la suma de dos vectores. El algoritmo está basado en la función axpy nivel 1[3], de la biblioteca BLAS[4] que resuelve la ecuación:\n","\n","<center>$Y=\\alpha X + Y$</center>\n","\n","Su objetivo es enseñar a los alumnos como se utiliza Python [2] la plataforma Colab[1] y CUDA[5,6]. Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."]},{"cell_type":"markdown","source":["### 3.1.1. Preguntas del ejercicio\n","a) El programa del punto 3.1.2 se encuentra dividido en bloques, que se identifican con nombres de colores. El problema consiste en ordenar los bloques, ya que se encuentran desordenados. Para ello, haga foco en cada celda y utilice las flechas $\\uparrow$ y $\\downarrow$, para reorganizar los bloques según el orden correcto.\n","\n","Nombre del bloque | Orden correcto\n","------------------|----------------\n","Verde             | \n","Rosa              | \n","Blanco            | \n","Amarillo          | \n","Gris              | \n","Naranja           | \n","Violeta           | \n","Negro             | \n","Rojo              | \n","Azul              | \n","\n","\n","*Tips:* Para ejecutar todas las celdas, ocúltelas con la flecha $\\downarrow$ que está al lado del título \"3.1.2 Ejecución del programa\".\n","\n","b) *Punto opcional:* Para verificar que el cálculo en GPU (junto con sus etapas) es correcto. Desarrolle la función axpy en forma secuencial (en lenguaje python) y compare los vectores resultados. \n","\n","---\n","\n","**NOTA**: Si ya verificó que todo funciona bien continue:\n","\n","c) Realice pruebas para diferentes valores de ```cantidad_N``` (500, 5.000, 50.000, 500.000 y 5.000.000). Compare los resultados con los obtenidos en el ejercicio 1.2.1 (OpenMP y secuencial).\n","\n","  Tamaño | Tiempo secuencial | Tiempo openmp | Tiempo GPU\n","---------|-------------------|---------------|------------\n","     500 |                   |               |\n","   5.000 |                   |               |\n","  50.000 |                   |               |\n"," 500.000 |                   |               |\n","5.000.000|                   |               |\n","\n","d) A la comparación anterior, incluya como impactan el SpeedUP y Eficiencia al usar GPU.\n","\n","e) A la comparación anterior, analice como fueron aumentando las dimensiones. ¿Se desperdiciaron muchos hilos? ¿Cómo se podría instanciar una cantidad de hilos exactamente igual al tamaño del vector?\n","\n","f) ¿Cómo hace el programa, para almacenar el resultado en el vector ```r_cpu```, si este vector nunca se parametriza en el kernel?\n","\n","g) Compare la función del kernel con la función ```axpy()``` del ejercicio 1.2.2 (OpenMP). ¿Qué cambios nota en el algoritmo? ¿El índice funciona igual? ¿Qué paso con el ciclo for en la función del kernel?\n"],"metadata":{"id":"nC_ZBz6V1Za8"}},{"cell_type":"markdown","metadata":{"id":"NzQaWRTtc1Zj"},"source":["---\n","### 3.1.2 Ejecución del programa"]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque VERDE\n","\n","# GPU - Copio el resultado desde la memoria GPU.\n","cuda.memcpy_dtoh( r_cpu, y_gpu )\n","\n","# Fin bloque VERDE\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"pO8xdiTS7JXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque ROSA\n","\n","from datetime import datetime\n","\n","tiempo_total = datetime.now()\n","\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule\n","\n","import numpy\n","\n","# Definición de función que transforma el tiempo en  milisegundos \n","tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n","\n","# Fin bloque ROSA\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"B0EX0dbj6jbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque BLANCO\n","\n","# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n","dim_hilo = 256\n","dim_bloque = int( (cantidad_N+dim_hilo-1) / dim_hilo )\n","\n","# Fin bloque BLANCO\n","# ------------------------------------------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9flEJpr687d","executionInfo":{"status":"ok","timestamp":1654031150772,"user_tz":180,"elapsed":291,"user":{"displayName":"Waldo Adolfo Valiente","userId":"07720288480485820277"}},"outputId":"666c7e87-8b3b-48c2-fa73-41842e6c2239"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thread x:  256 , Bloque x: 1954\n"]}]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque AMARILLO\n","\n","# #@title 3.1 Parámetros de ejecución { vertical-output: true }\n","\n","cantidad_N =   500000#@param {type: \"number\"}\n","alfa =   1#@param {type: \"number\"}\n","\n","# Fin bloque AMARILLO\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"O0MwIh186n3y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque GRIS\n","\n","# CPU - reservo la memoria GPU.\n","x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n","y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n","\n","# GPU - Copio la memoria al GPU.\n","cuda.memcpy_htod( x_gpu, x_cpu )\n","cuda.memcpy_htod( y_gpu, y_cpu )\n","\n","# Fin bloque GRIS\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"5VMOeuR06wNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z74FNbCszDmw"},"source":["#---------------------------\n","# Inicio bloque NARANJA\n","#\n","#  Armado del ambiente (Ojo)\n","\n","!pip install pycuda\n","\n","# Fin bloque NARANJA\n","# ------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque VIOLETA\n","\n","x_cpu = numpy.random.randn( cantidad_N )\n","x_cpu = x_cpu.astype( numpy.float32() )\n","\n","y_cpu = numpy.random.randn( cantidad_N )\n","y_cpu = y_cpu.astype( numpy.float32() )\n","\n","r_cpu = numpy.empty_like( x_cpu )\n","\n","# Fin bloque VIOLETA\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"hxhF76_b6rgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque NEGRO\n","\n","tiempo_total = datetime.now() - tiempo_total\n","\n","print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n","print( \"Cantidad de elementos: \", cantidad_N )\n","print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n","print( \"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n","print( \"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n","\n","# Fin bloque NEGRO\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"xBKZsSTg7LGz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio bloque ROJO\n","\n","tiempo_gpu = datetime.now()\n","\n","#TODO: Ojo, con los tipos de las variables en el kernel.\n","kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n","\n","tiempo_gpu = datetime.now() - tiempo_gpu\n","\n","# Fin bloque ROJO\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"oFyLBzPg7EyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Inicio del bloque AZUL\n","\n","module = SourceModule(\"\"\"\n","__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n","{\n","  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n","  if( idx < n )\n","  {\n","    Y[idx]  = alfa*X[idx] + Y[idx];\n","  }\n","}\n","\"\"\") \n","# CPU - Genero la función kernel.\n","kernel = module.get_function(\"kernel_axpy\")\n","\n","# Fin del bloque AZUL\n","# ------------------------------------------------------------------------------"],"metadata":{"id":"al5Igv1N67kx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6hn6HOCYEjyY"},"source":["---\n","# Bibliografia\n","\n","[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n","\n","[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n","\n","[3] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n","\n","[4] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n","\n","[5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n","\n","[6] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)\n","\n","\n"]}]}